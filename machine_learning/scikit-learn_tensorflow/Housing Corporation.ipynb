{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Final Predictions: [ 485664.16666667  263603.33333333  206876.66666667 ...,  260836.66666667\n",
      "  174733.33333333  117650.        ]\n",
      "Final RMSE: 48512.71504799674\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hashlib #to create unique train & test split instances\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from six.moves import urllib\n",
    "%matplotlib inline\n",
    "\n",
    "DOWNLOAD_ROOT='https://raw.githubusercontent.com/ageron/handson-ml/master/'\n",
    "HOUSING_PATH='datasets/housing'\n",
    "HOUSING_URL=DOWNLOAD_ROOT + HOUSING_PATH + '/housing.tgz'\n",
    "\n",
    "# download housing data\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, 'housing.tgz')\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "# load housing data in panda DataFrame\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, 'housing.csv')\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "#creates a unique hash\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "# create a test set\n",
    "def split_train_set(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedroom_ix, population_ix, household_ix = 3,4,5,6\n",
    "\n",
    "#Custom Transformer\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): #no *args or **kwargs to get methods: get_params, set_params\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix]/X[:, household_ix]\n",
    "        population_per_household = X[:, bedroom_ix] / X[:, rooms_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedroom_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "#Allows to feed a Panda DataFrame directly into the pipeline instead of extracting numerical columns into Numpy array\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "#fetch_housing_data()\n",
    "\n",
    "print('Start')\n",
    "housing = load_housing_data()\n",
    "\n",
    "#stratifying the data \n",
    "housing['income_cat'] = np.ceil(housing['median_income']/1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)\n",
    "#data description\n",
    "#housing.info()\n",
    "\n",
    "#get distinct catego;ries\n",
    "#housing['ocean_proximity'].value_counts()\n",
    "\n",
    "#get summary of numerical attributes\n",
    "#housing.describe()\n",
    "\n",
    "# Plot histogram of each numerical attribute\n",
    "# housing.hist(bins=50, figsize=(20,15))\n",
    "# plt.show()\n",
    "\n",
    "# train_set, test_set = split_train_set(housing, 0.2)\n",
    "\n",
    "# print('train: {0}, test: {1}'.format(len(train_set), len(test_set)))\n",
    "\n",
    "housing_with_ids = housing.reset_index()\n",
    "train_set, test_set = split_train_test_by_id(housing_with_ids, 0.2, 'index')\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "strat_train_set = strat_test_set = None\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop('income_cat', axis=1, inplace=True)\n",
    "\n",
    "housing = strat_train_set.copy()\n",
    "#s = district's populatin\n",
    "#c = color - represents the price\n",
    "\n",
    "# housing.plot(kind='scatter', x='longitude', y='latitude', alpha=0.4,\n",
    "#             s=housing['population']/100, label='population', figsize=(10,7),\n",
    "#             c='median_house_value', cmap=plt.get_cmap('jet'), colorbar=True,)\n",
    "#plt.legend()\n",
    "    \n",
    "#calculating standard correlation coefficient between every pair of attributes\n",
    "# corr_matrix = housing.corr()\n",
    "# corr_matrix['median_house_value'].sort_values(ascending=False)\n",
    "# housing['income_cat'].value_counts()/len(housing)\n",
    "\n",
    "#Visualizing standard correlation\n",
    "# from pandas.plotting import scatter_matrix\n",
    "# attributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']\n",
    "# scatter_matrix(housing[attributes], figsize=(12, 8))\n",
    "\n",
    "#housing.plot(kind='scatter', x='median_income', y='median_house_value', alpha=0.1)\n",
    "\n",
    "#Combining interesting attributes\n",
    "housing['rooms_per_household'] = housing['total_rooms']/housing['households']\n",
    "housing['bedrooms_per_room'] = housing['total_bedrooms']/housing['total_rooms']\n",
    "housing['population_per_household'] = housing['population']/housing['households']\n",
    "\n",
    "corr_matrix = housing.corr()\n",
    "#corr_matrix['median_house_value'].sort_values(ascending=False)\n",
    "\n",
    "#Preparing Data/Clean up\n",
    "housing = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "#Take care of missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='median')\n",
    "\n",
    "#since median can only be computed on numerical fields, we drop ocean_proximity object\n",
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "#training imputer\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "#estimator learned parameter\n",
    "# imputer.statistics_\n",
    "#housing_num.median().values\n",
    "\n",
    "#Using trained (median) imputer to transformed data by replacing missing values\n",
    "X = imputer.transform(housing_num)\n",
    "\n",
    "#converting text labels to numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "housing_cat = housing['ocean_proximity']\n",
    "housing_cat_encoded = encoder.fit_transform(housing_cat)\n",
    "#housing_cat_encoded\n",
    "# print(encoder.classes_)\n",
    "#Creating a one-hot encoder to avoid misinterpretation of encoded categories\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\n",
    "\n",
    "#Shothand to apply both transformations: text categories to integer then integer to one-hot vectors\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot\n",
    "\n",
    "#Using custom transformer\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "#Using Pipeline to order data transformation steps\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', Imputer(strategy='median')), \n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('label_binarizer', LabelBinarizer()),\n",
    "])\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline)\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared.shape\n",
    "# housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "#Training Model #1: LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "#Evaluating Model\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "# print('Predictions: {}'.format(lin_reg.predict(some_data_prepared)))\n",
    "# print('Labels: {}'.format(list(some_labels)))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared) #model underfits the data\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "#lin_rmse\n",
    "\n",
    "#Training (more powerful) Model #2: DecisionTree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "# tree_rmse\n",
    "\n",
    "\n",
    "#Cross-Validation K-fold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# #Linear Regression\n",
    "# lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring='neg_mean_squared_error',\n",
    "#                             cv=10)\n",
    "# lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "# #DecisionTree\n",
    "# scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring='neg_mean_squared_error',\n",
    "#                         cv=10)\n",
    "# tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "# def display_scores(name, scores):\n",
    "#     print('-------------------{}-------------------'.format(name))\n",
    "#     print('Scores: {}'.format(scores))\n",
    "#     print('Mean: {}'.format(scores.mean()))\n",
    "#     print('Standard deviation: {}'.format(scores.std()))\n",
    "\n",
    "# #Uinsg Model #3:Forest regressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# forest_reg = RandomForestRegressor()\n",
    "# forest_reg.fit(housing_prepared, housing_labels)\n",
    "# forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring='neg_mean_squared_error',\n",
    "#                         cv=10)\n",
    "# forest_rmse_scores = np.sqrt(-forest_scores)\n",
    " \n",
    "# display_scores('Linear Regressor', lin_rmse_scores)\n",
    "# display_scores('DecisionTree Regressor', tree_rmse_scores)\n",
    "# display_scores('RandomForest Regressor', forest_rmse_scores)\n",
    "                             \n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30],'max_features': [2,4,6,8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]},\n",
    "]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "cvres = grid_search.cv_results_\n",
    "# print('Best params: {}'.format(grid_search.best_params_))\n",
    "# print('Best estimator: {}'.format(grid_search.best_estimator_))\n",
    "\n",
    "# for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "#     print(np.sqrt(-mean_score), params)\n",
    "\n",
    "# feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "# print('Feature importances: {}'.format(feature_importances))\n",
    "\n",
    "# extra_attribs = ['rooms_per_hhold', 'pop_per_hhold', 'bedrooms_per_room']\n",
    "# cat_one_hot_attribs = list(encoder.classes_)\n",
    "# attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "# print(sorted(zip(feature_importances, attributes), reverse=True))\n",
    "\n",
    "#Final Model\n",
    "final_model = grid_search.best_estimator_\n",
    "X_test = strat_test_set.drop('median_house_value', axis=1)\n",
    "y_test = strat_test_set['median_house_value'].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "print('Final Predictions: {}'.format(final_predictions))\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print('Final RMSE: {}'.format(final_rmse))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5 (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
